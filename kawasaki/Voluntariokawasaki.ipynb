{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d42af84",
   "metadata": {},
   "source": [
    "# Implementación del algoritmo de Metrópolis para el modelo de Ising 2D con dinámica de Kawasaki\n",
    "\n",
    "El modelo de Ising fue desarrollado para analizar el comportamiento colectivo de los espines en materiales ferromagnéticos y  comprender cómo surgen fenómenos macroscópicos, como la magnetización, a partir de interacciones microscópicas entre espines vecinos. En este modelo, los materiales ferromagnéticos se representan como una red de espines, donde cada espín puede tomar dos valores posibles (+1 o -1).\n",
    "\n",
    "\n",
    "En la dinámica de Kawasaki se selecciona aleatoriamente un par de espines vecinos y se intercambian sus valores con una probabilidad de transición de un estado a otro determinada por el criterio de Metrópolis, que depende de la variación de energía asociada al intercambio y de la temperatura del sistema. En esta dinámica la cantidad de espines positivos y negativos permanece constante, como ocurre en sistemas cerrados. \n",
    "\n",
    "En las simulaciones, la magnetización total se ha mantenido constante durante la evolución (nula debido a que se ha inicializado a este valor). Se ha observado que el sistema puede experimentar una transición de fase en la temperatura crítica. Para temperaturas menores que la crítica, la red se organiza en agrupaciones de espines del mismo signo (dominios), con magnetizaciones opuestas, de modo que la magnetización global sigua siendo nula."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca21d9c",
   "metadata": {},
   "source": [
    " \n",
    " \n",
    "## SIMULACIONES\n",
    "\n",
    " La siguiente simulación muestra la evolución de una red de tamaño $N=64$ a una temperatura $T=4$ con 10000 pasos Monte Carlo. La configuración inicial es una red ordenada de espines de magnetización neta nula, con mitad de espines positivos y mitad negativos. Se observa que para temperaturas mayores que la temperatura crítica, el material ferromagnético pierde su magnetismo, comportándose como un material paramagnético, encontrándose la red completamente desordenada.\n",
    "\n",
    " <video width=\"600\" controls>\n",
    "  <source src=\"T=4, ordenada.mp4\" type=\"video/mp4\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84909eaf",
   "metadata": {},
   "source": [
    "\n",
    "A continuación se muestra la evolución de una red de tamaño $N=64$ a una temperatura de $T=1$ con 10000 pasos Monte Carlo. La configuración inicial es una red de magnetización neta nula con espines desordenados. Se aprecia la formación rápida de dominios magnéticos, característicos de los materiales ferromagnéticos.\n",
    "\n",
    "<video width=\"600\" controls>\n",
    "  <source src=\"T=1, dominios.mp4\" type=\"video/mp4\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1a5f7b",
   "metadata": {},
   "source": [
    "Los materiales ferromagnéticos están formados por regiones llamadas dominios magnéticos en las que los dipolos se alinean en la misma dirección, de manera que cada dominio presenta un momento dipolar neto. \n",
    "En presencia de un campo externo, los momentos dipolares de los dominios giran de manera que se alinean parcialmente con el campo. El efecto es la creación de un momento dipolar magnético neto que se dirige a lo largo del campo magnético aplicado. El momento dipolar neto es mucho mayor que el de un material paramagnético y los dominios no se desalinean por agitación térmica. Para estos materiales, existe una magnetización remanente si se elimina el campo externo (imán permanente).\n",
    "\n",
    " \n",
    "En el caso de los materiales paramagnéticos los dipolos (que suponen un momento magnético) se alinean parcialmente en la dirección de un campo aplicado en el material de manera que el campo aplicado se refuerza en su interior.\n",
    "Sin embargo, la magnetización  es débil y al aumentar la temperatura las colisiones térmicas de los átomos interfieren en la alineación de los dipolos magnéticos. Como resultado, solo una pequeña fracción de los dipolos están alineados en un instante de tiempo. Por tanto, para estos materiales no hay efectos residuales al eliminarse el campo exterior y, además,  al aumentar la temperatura todo los dipolos se orientan al azar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f781faec",
   "metadata": {},
   "source": [
    "La siguiente simulación muestra la evolución de una red también de $N=64$ para la temperatura crítica  teórica del sistema a ese tamaño $T_c=1.962$. La simulación también se ha realizado para 10000 pasos Monte Carlo. \n",
    "\n",
    "<video width=\"600\" controls>\n",
    "  <source src=\"Tcritica.mp4\" type=\"video/mp4\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e7f028",
   "metadata": {},
   "source": [
    "## Energía por partícula \n",
    "\n",
    "El sistema evoluciona hacia el estado que minimize la energía libre de Helmholtz:\n",
    "\n",
    "\\begin{equation}\n",
    "    A=U-TS\n",
    "\n",
    "\\end{equation}\n",
    "\n",
    "A temperatura bajas, predomina la contribución de la energía interna $U$, luego para que se minimize la energía libre, los espines se orientarán en una misma dirección y el material se magnetizará espontáneamente (material ferromagnético). \n",
    "\n",
    "Pero al aumentar la temperatura el término -TS predomina, por lo que para minimizar la energía libre la entropía debe maximizarse, dando lugar a una fase desordenada (material paramagnético). \n",
    "La temperatura crítica es precisamente aquella para la cual la contribución de  la energía interna y la entropía a la energía libre es la misma.\n",
    "\n",
    "En el modelo de ising la energía de la configuración de espines (en ausencia de campo externo) se calcula mediante la expresión: \n",
    "\n",
    "$E(S) = -\\frac{1}{2} \\sum_{i=1}^{N} \\sum_{j=1}^{N} s(i, j) \\left[ s(i, j+1) + s(i, j-1) + s(i+1, j) + s(i-1, j) \\right]$\n",
    "\n",
    "En la expresión vemos que para que se minimize la energía todos los espines tienen que orientarse en una misma dirección (+1 ó -1), pero como la magnetización total del sistema se conserva, se formarán dominios de espines. La energía máxima ($E_{\\text{min}}$=0) se alcanzará a temperaturas muy altas, cuanto los espines se encuentren completamente desordenados.\n",
    "\n",
    "La energía media por partícula $e$ se ha calculado como el valor promedio de la energía total de la configuración dividido entre $2N^2$, es decir:\n",
    "\n",
    "$e = \\frac{\\langle E \\rangle}{2N^2}$\n",
    "\n",
    "donde $\\langle E \\rangle$ es la energía promedio de la configuración y $N$ es la longitud lateral de la red cuadrada. \n",
    "\n",
    "La siguiente gráfica muestra la energía media por partícula en función de la temperatura para 100000 pasos Monte Carlo. La configuración incial de la red considerada es magnetización neta nula con mitad de espines positivos y negativos. \n",
    "\n",
    "![Calor especifico](energia_particula.png)\n",
    "\n",
    "Se observa que a temperaturas muy altas, cuando la red se encuentra totalmente desordenada, la energía tiende a cero, y a temperaturas bajas la energía se minimiza. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029b68e9",
   "metadata": {},
   "source": [
    "## Calor específico y magnetización\n",
    "Para el límite termodinámico $N \\to \\infty$, en la temperatura crítica la magnetización presenta una transición abrupta y el calor específico diverge. \n",
    "\n",
    "Sin embargo, el modelo de Ising bidimensional, la capacidad calorífica no diverge para sistemas finitos, sino que su valor máximo crece logarítmicamente con el tamaño de la red $C_v \\sim \\ln N$. Aunque teóricamente, para un sistema infinito, la capacidad calorífica diverge en la temperatura crítica (solución de Onsager), en la práctica, incluso para sistemas tan grandes como el número de Avogadro, nunca alcanza una divergencia real.\n",
    "\n",
    "  La siguiente gráfica muestra los valores del calor específico obtenidos en función de la temperatura para 100000 pasos Monte Carlo y para dos valores distintos del tamaño de la red $N$. La configuración incial de la red considerada es magnetización neta nula con mitad de espines positivos y negativos. \n",
    "\n",
    "  Se observa que el pico de la capacidad calorífica se vuelve más agudo y se acerca a la temperatura crítica a medida que el sistema crece. \n",
    "\n",
    "  ![Calor especifico](caloresp2.png)\n",
    "\n",
    "  La gráfica obtenida muestran un comportamiento similar al predicho teóricamente, confirmando la existencia de una transición de fase en el rango (2 < T < 3). Para mejorar la precisión en la determinación de la temperatura crítica, se han obtenido más valores de la magnetización dentro de la región crítica.\n",
    "\n",
    "  A continuación se muestra otra gráfica del calor específico en función de $T$ para otros valores del tamaño de la red. Se ha intentado realizar simulaciones con redes de tamaños más grandes para extrapolar los resultados al límite termodinámico. \n",
    "\n",
    "  ![Calor especifico](caloresp5.png)\n",
    "  \n",
    "  En las gráficas, al ser el calor específico una magnitud intensiva el máximo no debería desplazarse conforme crece el valor de $N$ y las tres curvas deberían coincidir. \n",
    " A diferencia de la solución exacta de Onsager, para sistemas finitos el valor máximo de la capacidad calorífica crece logarítmicamente con el tamaño del sistema. En todo caso, si representásemos la capacidad calorífica, al crecer el pico con el logaritmo natural de $N$, los máximos deberían crecer más lentamente. Sin embargo, como el calor específico es intensivo el máximo no debería desplazarse hacia la derecha al crecer el tamaño de la red. \n",
    "\n",
    " La expresión teóricas que cuantifican cuánto varían la temperatura crítica con el tamaño del sistema es:\n",
    "\n",
    "$\\beta_c = \\beta_{\\text{ONS}} \\left( 1 + \\frac{5}{4 \\sqrt{N}} \\right)$\n",
    "\n",
    "donde $\\beta_{\\text{ONS}}$ es el valor obtenido de $\\beta$ en la solución exacta de Osanger.\n",
    "\n",
    "A partir de la expresión anterior se deduce que la diferencia en la temperatura crítica experimental respecto a la teórica crece con ${\\sqrt{N}}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675cf756",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "La siguiente tabla muestra los valores obtenidos del máximo del calor específico y la temperatura a la que se da este máximo, así como el valor de la temperatura crítica calculada mediante la expresión anterior, para distintos valores de $N$.\n",
    "\n",
    " |  $N$ | $C_v$  | $T$   | $T_c$   |\n",
    "|------------------------|--------|-------|---------|\n",
    "| 32                     | 1.12   | 2.5   | 1.858   |\n",
    "| 64                     | 4.48   | 2.5   | 1.962   |\n",
    "| 128                    | 43.19  | 3.0   | 2.04    |\n",
    "\n",
    "\n",
    "Por otro lado, en un sistema finito la transición de la magnetización en la temperatura crítica se suaviza, lo que dificulta su identificación exacta. En la siguiente gráfica se muestran los valores de la magnetización en función de la temperatura. Los datos se han obtenido para los mismos pasos Monte Carlo y misma configuración inicial de espines. \n",
    "\n",
    " ![Calor especifico](magnetizacionvstemperatura.png)\n",
    "\n",
    "Cerca de la temperatura crítica ciertas funciones termodinámicas $G(T)$  exhiben un comportamiento característico que sigue una ley de potencias:\n",
    "\n",
    "$G(T) \\sim \\left| \\frac{T - T_c}{T_c} \\right|^d$\n",
    "\n",
    "donde $d$ es  el exponente crítico y varía según la función considerada. Estos exponentes  reflejan cómo cambian las propiedades del sistema en las proximidades del punto crítico.\n",
    "\n",
    "En concreto, la magnetización sigue la ley de potencias:\n",
    "\n",
    "$ M(T) \\sim (T_c - T)^\\beta \\quad \\text{para } T < T_c $\n",
    "\n",
    "Obteniendo los valores de la magnetización M(T) para diferentes temperaturas en el rango cercano a $T_c$ y tomando el logaritmo de ambos lados de la ecuación para linealizarla: $ \\log(M) = \\beta \\log(T_c - T) + \\text{constante} $, podemos usar método de ajuste  para encontrar los valores de $T_c$ y $\\beta$ que mejor se ajusten a los datos obtenidos.\n",
    "\n",
    " En la siguiente imagen se grafica  $\\log(M)$ frente a $\\log(T_c - T)$ para verificar si los datos siguen una línea recta. Se ha utilizado el valor de la temperatura crítica teórico para un sistema infinito ($T_c=2,269$), ya que a partir de los valores obtenidos de la magnetización no se puede determinar el valor de la temperatura crítica del sistema con precisión. Los valores de la magnetización tomados son los datos experimentales en torno a esa temperatura crítica. El resultado obtenido no ha sido el esperado, ya que los valores representados no siguen una tendencia lineal, siendo el coeficiente de Pearson de -0.7704. \n",
    "\n",
    " ![Calor especifico](expcriticos.png)\n",
    "\n",
    "El exponente crítico obtenido $\\beta_{exp}= -0.7704$ discrepa bastante del teórico, tomando además un valor negativo. Para la magnetización el exponente crítico teórico es $\\beta=1/8$. \n",
    "\n",
    "Para el calor específico $\\alpha=0$, debido a que en la temperatura crítica presenta una divergencia de tipo logarítmica.\n",
    "\n",
    "## Susceptibilidad ##\n",
    "\n",
    "A continuación se muestran los valores de la susceptibilidad obtenidos para diferentes temperaturas, con $100000$ pasos montecarlo y una configuración ordenadad de espines, con la mitad positivos y la mitad negativos. Se observa que a temperaturas altas, cuando la red está desordenada y el sistema se comporta como un material paramagnético, la susceptibilidad toma valores muy bajos. \n",
    "\n",
    "![sus](susceptibilidad.png)\n",
    "\n",
    "En las gráficas obtenidas para la magnetización, calor específico y susceptibilidad, la temperaturas para las que se da el máximo son mayores que las predichas teóricamente para el tamaño del sistema $N$. Las discrepancias parecen ser mayores para el caso del calor específico, y los mejores resultados se observan en esta gráfica de la susceptibilidad. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ccf3081",
   "metadata": {},
   "source": [
    "## Densidad de espines \n",
    "\n",
    "En esta sección se estudia cómo varía la densidad de espines por fila (en la dirección y)  en función de la temperatura, considerando diferentes tamaños de red. La densidad de espines positivos se define como la razón entre el número de espines +1 en una fila y el número total de espines -1 en esa misma fila, es decir,\n",
    "\n",
    " $\\rho_{+} = \\frac{\\text{número de espines +1 }}{\\text{número total de espines fila}}$\n",
    "\n",
    "De manera análoga se obtiene la densidad de espines negativos, de forma que la suma de ambas densidades en cada fila siempre es igual a 1.\n",
    "\n",
    "La siguiente gráfica muestra la densidad de espines, tanto negativos como positivos, en función de la temperatura $T$ para la fila que ocupa la posición $N/4$. Se han realizado 100000 pasos Monte Carlo y la configuración inicial de la red es magnetización nula con la mitad de espines positivos y negativos. \n",
    "\n",
    " ![Calor especifico](densidad%20espines.png)\n",
    "\n",
    "A bajas temperaturas, se observa una clara predominancia de espines negativos, lo que indica un sistema ordenado. Este comportamiento es característico del régimen ferromagnético, donde se forman dominios de espines alineados, minimizándose la energía.\n",
    "\n",
    "Con el aumento de la temperatura, el sistema se vuelve progresivamente más desordenado debido a la agitación térmica, que favorece configuraciones con mayor entropía. En consecuencia, las densidades de espines +1 y -1 tienden a igualarse, aproximándose ambas al valor ρ=0.5. Este es el régimen paramagnético, en el que los espines adoptan orientaciones aleatorias.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238f4260",
   "metadata": {},
   "source": [
    "## Coste Computacional\n",
    "\n",
    "La energía del sistema se calcula mediante la función`calcularEnergiaLocal`. Cuando se propone intercambiar dos espines vecinos en las posiciones $(x_1, y_1)$ y $(x_2, y_2)$, la función calcula la energía local de ambos espines antes y después del intercambio. Para cada espín, solo se consideran las interacciones con sus vecinos más cercanos, excluyendo al espín con el que se intercambia, ya que la contribución mutua entre ambos se cancela al calcular la diferencia de energía. Así, la variación de energía $\\Delta E$ se obtiene sumando las interacciones de cada espín con sus otros tres vecinos, tanto antes como después del intercambio. Se hacen 6 evaluaciones antes y después del intercambio, en total 12 evaluaciones. Este método permite calcular de manera eficiente el cambio de energía relevante para el criterio de Metrópolis, sin necesidad de recorrer toda la red.\n",
    "\n",
    "Para obtener la energía total de la configuración para cada iteración, se calcula la energía total inicial y se va sumando a esta cantidad la diferencia de energía local al realizar el intercambio.\n",
    "\n",
    "Además, se ha evaluado la convergencia del sistema calculando la desviación de la energía del promedio de la misma realizado 100 pasos Monte Carlo. Cuando la desviación es menor que un valor umbral, se considerada que se ha alcanzado la convergencia y la simulación para. El valor umbral se ha ido modificando según la temperatura del sistema pero en general ronda en el intervalo (20,30).\n",
    "\n",
    "La siguiente gráfica muestra los valores de la energía total del sistema promediada cada paso montecarlo para una red de $N=64$ inicialmente desordenada y con magnetización neta nula, y a una temperatura $T=1$. La convergencia se alcanza en el paso 1000 con un valor umbral de 20. \n",
    "\n",
    "![Calor especifico](convergencia.png)\n",
    "\n",
    "A continuación, se representa el tiempo de ejecución del programa en función del tamaño de la red para un programa en el que se ha introducido un break (línea 417) en el bucle que recorre un paso Monte Carlo, y para otro programa idéntico, salvo que no incluye esta mejora. \n",
    "\n",
    "Para la opción menos eficiente, sin incluir el break, en cada paso de Monte Carlo, el programa intenta realizar múltiples intercambios de espines, incluso después de que uno ya ha sido aceptado. Esto introduce un coste cuadrático con respecto al tamaño de la red.\n",
    "\n",
    "Es más eficiente no seguir intentando más intercambios en un paso de Monte Carlo una vez que un intercambio se ha realizado.\n",
    "En ese caso, el tiempo de ejecución del programa crece linealmente con N, no escala con el tamaño de la red.\n",
    "\n",
    "\n",
    "![Calor especifico](eficiencia_break.png)\n",
    "\n",
    "La siguiente gráfica muestra el tiempo de ejecución de la simulación para una temperatura $T=1$ utilizando distintas opciones de compilación con el compilador CLANG del Joel y con mi ordenador.\n",
    "\n",
    "\n",
    "![Calor especifico](optimizacion.png)\n",
    "\n",
    "\n",
    "\n",
    "O1 genera un código optimizado más pequeño que las opciones O2 y O3. Por tanto, simplifica el código y evita técnicas que lo agranden. Puede dar más prioridad a que el programa ocupe menos memoria que a la eficiencia de la CPU. Así, para tamaños grandes de la red, da el peor rendimiento. Por otro lado, utilizando O2 tenemos un equilibrio entre tamaño y velocidad.\n",
    "\n",
    "O3  utiliza optimizaciones más agresivas de bucles y acceso a memoria, y se recomienda para procesar grandes conjuntos de datos. Sin embargo, el exceso de optimización puede, en ocasiones, ralentizar el tiempo de ejecución del programa en comparación con O2. \n",
    "\n",
    "En la gráfica vemos que O3 es peor que O2, incluso peor que O1, para N bajas (N=32) pero existe una mejora considerable utilizando O3 para N altas (N=150). Para tamaños de la red intermedias, es más conveniente utilizar O2.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53224af",
   "metadata": {},
   "source": [
    "Las características de JOEL son: \n",
    "\n",
    "Modelo de la CPU: AMD EPYC 7401P 24-Core Processor\n",
    "\n",
    "CPUS: 48 núcleos disponibles\n",
    "\n",
    "Memoria RAM usada: 2,9Gi\n",
    "\n",
    "Memoria RAM total: 62Gi\n",
    "\n",
    "Frecuencia de reloj:\n",
    "CPU max MHz:                          2000,0000\n",
    "CPU min MHz:                          1200,0000\n",
    "\n",
    "Nombre y versión del sistema operativo: \"Ubuntu 22.04.5 LTS\"\n",
    "\n",
    "Para mi ordenador las características son: \n",
    "\n",
    "Procesador: 11 th Gen Intel(R) Core(TM) i7-1195G7  2.92 GHz\n",
    "\n",
    "RAM instalada: 8.00 GB\n",
    "\n",
    "CPUS: 8 núcleos disponibles. \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ef3c80",
   "metadata": {},
   "source": [
    "## Errores ##\n",
    "\n",
    "\n",
    "\n",
    "Para un conjunto $\\{x_k\\}_{k=1}^{M}$ de $M$ mediciones independientes de una magnitud $x$, el valor promedio se define como:\n",
    "\n",
    "$$\n",
    "\\langle x \\rangle = \\frac{1}{M} \\sum_{k=1}^{M} x_k\n",
    "$$\n",
    "\n",
    "Hemos realizado el promedio de las magnitudes, como el calor especifico o la energía media, cada 100 pasos Monte Carlo para que las variables estén decorrelacionadas. \n",
    "\n",
    "La dispersión de las mediciones respecto a este promedio puede cuantificarse mediante la varianza muestral:\n",
    "\n",
    "$$\n",
    "\\mathrm{Var}(x) = \\frac{1}{M} \\sum_{k=1}^{M} (x_k - \\langle x \\rangle)^2\n",
    "$$\n",
    "\n",
    "y su raíz cuadrada corresponde a la desviación estándar, $s$, de la muestra.\n",
    "\n",
    "Para estimar la incertidumbre del valor medio, se introduce el error estándar de la media, definido como:\n",
    "\n",
    "$$\n",
    "\\delta x = \\frac{s}{\\sqrt{M}}\n",
    "$$\n",
    "\n",
    "Este error representa una medida de cuán preciso es el promedio calculado, y disminuye con el número de mediciones $M$. Se ha elegido el intervalo $\\langle x \\rangle \\pm \\delta x$ correspondiente a un nivel de confianza del 68% (1 sigma). Es decir, existe una probabilidad del 68% de que el valor verdadero de la magnitud se encuentre dentro de dicho intervalo si el experimento se repitiera múltiples veces bajo las mismas condiciones.\n",
    "\n",
    "Como los  tamaños de muestra elegidos son relativamente grandes, el valor de $\\delta x$ tiende a ser pequeño, por lo que en muchas representaciones las barras de error no son apreciables. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7628811",
   "metadata": {},
   "source": [
    "## Conclusión ##\n",
    "\n",
    "El comportamiento del sistema simulado en general se adecua a lo predicho teóricamente y se ha observado la transición del paramagnetismo al ferromagnetismo para temperaturas por debajo o mayores que la temperatura crítica, respectivamente. \n",
    "\n",
    "Sin embargo, no se ha podido estimar con precisión la temperatura crítica en función del tamaño de la red debido a que los valores de la magnetización obtenidos no parecen cumplir la ley de potencias esperada en torno a esta temperatura, obteniéndose un exponente crítico $\\beta$ que discrepa totalmente con el valor teórico. \n",
    "\n",
    "En general, podemos decir que los resultados han sido los esperados, observándose la formación de dominios a temperaturas bajas y de forma cualitativa se ha comprobado la tendencia de funciones termodinámicas como el calor específico o la magnetización en torno a la temperatura crítica. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d19c0e9",
   "metadata": {},
   "source": [
    "\n",
    "# Bibliografía\n",
    "- Una revisión del modelo de Ising y su aplicación en sociología a través del modelo de Sznajd.  \n",
    "  https://addi.ehu.es/bitstream/handle/10810/30543/TFG_Garcia_Berdote_Asier.pdf?sequence=1&isAllowed=y\n",
    "- The Analytical Expressions for a Finite-Size 2D Ising Model.\n",
    "M.Yu. Malsagov, I.M. Karandashev and B.V. Kryzhanovsky. https://arxiv.org/pdf/1706.02541\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
